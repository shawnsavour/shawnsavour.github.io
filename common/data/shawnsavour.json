{
  "name": "SON (SHAWN) CONG DO",
  "title": "Platform/DevSecOps Engineer",
  "phone": "+84 969 669 531",
  "perfil": "With over 6 years of experience in DevSecOps, I excel in leading cloud migrations, implementing DevSecOps practices, and automating security tasks.<br>I have deep expertise in AWS, Azure, GCP, and tools like Terraform, Kubernetes, and Packer.<br>I leverage Infrastructure as Code (IaC) best practices to create secure, scalable, and efficient infrastructure.<br>I champion GitOps for streamlined and reliable deployments.<br>My toolkit includes Vault Warden, Gitlab CI, ArgoCD, Hashicorp Vault, OPA Gatekeeper, Snyk, and Sonarqube for comprehensive security.<br>I ensure system performance with robust logging, tracing, and monitoring solutions.<br>My experience extends to designing hybrid cloud environments with secure communication and implementing best practices for organization and security.<br>I am confident in my ability to contribute to your organization's success by delivering secure, reliable, and scalable solutions.",
  "portfolios": [{
      "type": "Credly",
      "name": "Credly Badge",
      "link": "https://www.credly.com/users/son-do.1460d18d/badges/",
      "icon": "bi bi-c-circle-fill"
    },
    {
      "type": "LinkedIn",
      "name": "shawndo",
      "link": "https://www.linkedin.com/in/shawndo",
      "icon": "bi bi-linkedin"
    },
    {
      "type": "Github",
      "name": "shawnsavour",
      "link": "https://github.com/shawnsavour",
      "icon": "bi bi-github"
    },
    {
      "type": "Website",
      "name": "ShawnSavour.site",
      "link": "https://shawnsavour.site",
      "icon": "bi bi-globe"
    }
  ],
  "email": "sondc.workspace@gmail.com",
  "linkedin": "https://www.linkedin.com/in/shawndo",
  "github": "https://github.com/shawnsavour",
  "workExperience": [
    {
      "id": 0,
      "company": true,
      "position": "Senior DevOps Engineer",
      "employer": "VMO Group",
      "date": "Aug 2022 - Present · 2 yrs 6 mos",
      "type": "Work",
      "description": [
        "VMO Group is an outsourcing company that provides software development and IT services to clients across various industries.",
        "Awarded Employee of the Year for two consecutive years, recognizing outstanding performance and contributions to the company."
      ],
      "children": [2, 1, 5, 6, 7]
    },
    {
      "id": 1,
      "position": "Senior DevOps Engineer",
      "employer": "VMO Group",
      "date": "Aug 2022 - Present · 2 yrs 2 mos",
      "type": "Work",
      "description": [
        "As a DevOps engineer at VMO Group, my main role was to create and maintain dev environments for all Delivery Units in the company, using various technologies and best practices.",
        "• Set up and maintained a robust and secure on-premise Kubernetes system for deploying and managing containerized applications",
        "• Implemented a Ceph storage system to provide scalable and reliable storage for the Kubernetes clusters",
        "• Installed and configured Gitlab system to enable version control, continuous integration, and continuous delivery for the development teams",
        "• Integrated Gitlab dynamic runner system used IaC tools to manage Gitlab runner system with GitOps, which is a methodology that applies the principles of version control and automation to the entire software delivery pipeline to improve the efficiency, reliability, and security of the software delivery process at VMO Group",
        "• Provision and manage the Proxmox system, which is a virtualization platform that allows running multiple operating systems on a single host"
      ]
    },
    {
      "id": 2,
      "parent": 1,
      "position": "Platform Leader",
      "employer": "Zuellig Pharma",
      "date": "Oct 2023 - Present · 1 yr 4 mos",
      "type": "Work",
      "description": [
        "Zuellig Pharma, a leading healthcare services provider in Asia, has been at the forefront of healthcare distribution and services for over a century, operating in 16 markets and partnering with top pharmaceutical companies to serve over 200,000 medical facilities.",
        "Objective:",
        "The objective is to modernize and secure the cloud infrastructure by migrating from Azure to Google Cloud Platform (GCP) and implementing Kubernetes Engine for orchestration. This transition will follow best practices for organization and security (Fabric FAST, GKE best practices, GitOps) and leverage CloudSQL with Workload Identity for secure database management. An Infrastructure as Code (IaC) pipeline will automate infrastructure management.",
        "Responsibilities:",
        "• Lead the design and implementation of a secure and scalable cloud infrastructure on Google Cloud Platform",
        "• Architect and implement a hybrid cloud network environment using the Spoke and Hub model",
        "• Oversee the migration of all infrastructure from Azure to Google Cloud",
        "• Set up and maintain a robust Kubernetes system",
        "• Implement best practice organization models using Fabric FAST",
        "• Apply security best practices to the GKE system",
        "• Migrate and implement security measures with GitOps from AKS to GKE",
        "• Provision CloudSQL and implement SQLproxy with Workload Identity Authentication methods to ensure secure database connections",
        "• Develop and manage an IaC pipeline for automated infrastructure management"
      ]
    },
    {
      "id": 3,
      "position": "Senior DevOps Engineer",
      "employer": "BB Digital",
      "date": "Feb 2023 - May 2024 · 1 yr 4 mos",
      "type": "Freelance",
      "description": [
        "This role is responsible for securing and streamlining the company's software development and operations processes.",
        "Responsibilities:",
        "• Implement DevSecOps best practices throughout the software development lifecycle, utilizing tools like Vault Warden, Gitlab CI/ArgoCD, Terraform, KEDA/Kapenter, Hashicorp Vault/OPA GateKeeper, and Snyk/Sonarqube/Trivy/ZAP Operator to automate security tasks.",
        "• Monitor system performance and health using logging (Promtail, Loki, Grafana), tracing (ElasticSearch, Jaeger), and monitoring (Prometheus).",
        "• Utilize Automation WAF to automatically deploy and manage AWS WAF rules, safeguarding the company's web applications from common attacks."
      ]
    },
    {
      "id": 4,
      "position": "Senior DevSecOps Engineer",
      "employer": "BICBank Cambodia",
      "date": "Jan 2023 - Jul 2024 · 1 yr 2 mos",
      "type": "Freelance",
      "description": [
        "Led a comprehensive cloud migration to AWS for BIC Bank Cambodia, transforming their on-premises infrastructure for increased scalability, agility, and cost-efficiency.",
        "Technical Approach:",
        "• Migrate all on-premises banking platforms to AWS with a re-architect strategy",
        "• Design and implement landing zones for organizations with IAM Identity Central Active Directory",
        "• Design and implement hub and spoke hybrid network model",
        "• Implement Site to Site VPN and Software VPN with SSO Active Directory with Pritunl Enterprise",
        "• Implement all underlying infrastructure as EKS, RDS serverless, DynamoDB ...",
        "• Implement centralized security and monitoring in shared-service EKS cluster with Hashicorp Vault high availability, Prometheus with Thanos Multi cluster pattern.",
        "• Implement secret rotation and injection with Hashicorp Vault Injector high availability, directly pass secrets into the pod without storing them as secrets inside the cluster.",
        "• Implement distro-less images with smaller size, faster deployments, and potentially improved security.",
        "• Implement Istio gateway and service mesh with strict mTLS between microservices.",
        "• Implement Gitlab for 5000 users with hybrid architecture",
        "• Integrate GitLab dynamic runner system with GitOps managed declarative config",
        "• Implement a centralized pipeline template with many security layers in the pipeline, including SAST and SCA with Sonarqube, Trivy, Snyk, Docker Scout, ...and DAST with OWASP ZAP",
        "• Implement policy enforcement with Open Policy Agent GateKeeper with Centralized Policy Management, Admission Control Integration, Enforcing Best Practices and Compliance Enforcement to comply with internal security policies or external regulatory requirements (e.g., PCI-DSS, HIPAA)",
        "• Implement Security Automations for AWS WAF rules to protect your web applications from common attacks with Automation WAF (anti DDoS, Web Scan, XSS/SQL injection, Bot and IP restriction, ...)"
      ]
    },
    {
      "id": 5,
      "parent": 1,
      "position": "Senior DevSecOps Engineer",
      "employer": "Onqlave",
      "date": "Jun 2023 - Sep 2023 · 4 mos",
      "type": "Work",
      "description": [
        "As a DevSecOps engineer at OQL Company in Australia, I am responsible for ensuring the security and reliability of the company's Encryption as a Service platform on Google Cloud Platform. I work in a fully secured environment and use a landing zone approach with Google Cloud Foundation Fabric.",
        "My responsibilities include:",
        "• Implementing and managing DevSecOps best practices throughout the software development lifecycle, from code development to deployment and operations.",
        "• Using Google Cloud Platform security tools and services to protect the company's infrastructure, data, and applications.",
        "• Configuring and managing Google Cloud Foundation Fabric to create a secure landing zone for the Encryption as a Service platform.",
        "• Working with other engineers to automate security tasks and integrate security into the company's development and operations processes.",
        "• Monitoring the performance and security of the Encryption as a Service platform and responding to incidents promptly.",
        "I am a highly skilled and experienced DevSecOps engineer with a deep understanding of Google Cloud Platform security tools and services. I am also passionate about DevSecOps and am committed to delivering secure and reliable software."
      ]
    },
    {
      "id": 6,
      "parent": 1,
      "position": "Senior DevSecOps Engineer",
      "employer": "Dentity",
      "date": "Dec 2022 - Sep 2023 · 10 mos",
      "type": "Work",
      "description": [
        "Dentity provides secure and scalable authentication and authorization services for web and mobile applications.",
        "As the sole DevSecOps engineer, I integrate security into development and operations processes, including:",
        "• Managing secrets with Vault Warden",
        "• Automating deployments to AWS EKS with GitOps using Gitlab CI and ArgoCD",
        "• Implementing IaC best practices with Terraform",
        "• Autoscaling EKS clusters with KEDA and Kapenter",
        "• Managing and rotating secrets with Hashicorp Vault and enforcing policies with OPA GateKeeper",
        "• Using passwordless and credential-less patterns for secure connections",
        "• Performing SAST and DAST scans with Snyk, Sonarqube, Trivy, and ZAP operator",
        "• Monitoring system performance with Promtail, Loki, Grafana, ElasticSearch, Jaeger, and Prometheus",
        "• Deploying and managing AWS WAF rules with Automation WAF",
        "By following DevSecOps practices, I ensure Dentity delivers secure and reliable identity services on AWS."
      ]
    },
    {
      "id": 7,
      "parent": 1,
      "position": "DevOps Engineer",
      "employer": "GEM - Global Enterprise Mobility",
      "date": "Sep 2022 - Dec 2022 · 4 mos",
      "type": "Work",
      "description": [
        "Built a logging and tracing system on AWS to monitor and troubleshoot the performance and health of their applications",
        "• Used Fluent Bit to collect and forward logs from various sources to Loki",
        "• Used Loki to store and query the logs in a scalable and cost-effective way",
        "• Used Grafana to visualize and analyze the logs and metrics from Loki and other sources",
        "• Used OpenTelemetry to instrument and collect traces from the applications",
        "• Used AWS X-Ray to store and visualize the traces and identify bottlenecks and errors",
        "• Used CloudFormation to provision and manage the AWS resources for the logging and tracing system",
        "• Used HashiCorp Packer to create and configure custom AMIs for the EC2 instances running the applications"
      ]
    },
    {
      "id": 8,
      "company": true,
      "position": "DevOps Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "May 2021 - Jul 2022 · 1 yr 3 mos",
      "type": "Work",
      "description": [
        "Saltlux is a leading AI and big data company in South Korea, providing innovative solutions and services to various industries.",
        "Awarded Employee of the Year for outstanding performance and contributions to the company."
      ],
      "children": [9, 10, 11, 12]
    },
    {
      "id": 9,
      "position": "DevOps Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "Aug 2021 - Jul 2022 · 1 yr",
      "type": "Work",
      "description": [
        "• Used Google Kubernetes Engine (GKE) to deploy and manage a crawler system with 800 nodes on Google Cloud Platform (GCP)",
        "• Used Kafka to stream and process large amounts of data from the crawler system",
        "• Used Redis to store and access data in memory for fast performance",
        "• Used MongoDB to store and query structured and unstructured data",
        "• Used Loki, Promtail, and Grafana to monitor and visualize the logs and metrics of the crawler system and other components",
        "• Used best practices and tools to automate, secure, and optimize the DevOps workflow on GCP"
      ]
    },
    {
      "id": 10,
      "position": "C# Software Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "Oct 2021 - Jul 2022 · 10 mos",
      "type": "Work",
      "description": [
        "Personal Agent Desktop: Part of the Personal Agent project, personalized data mining, using resources from the user's own computer. Personal Agent desktop is in the presentation layer to manage the collected data, statistics and all source to collect of user. (hybrid app with Personal Agent web with more personal functions)",
        "Personal Agent windows services: Part of the Personal Agent project, personalized data mining, using resources from the user's own computer. The windows service will be responsible for checking the collection schedule and conducting highly personalized data collection."
      ]
    },
    {
      "id": 11,
      "position": "Javascript Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "Aug 2021 - Jul 2022 · 1 yr",
      "type": "Work",
      "description": [
        "Account control extension: Chromium-core extension for obtaining account-based cookies for the collection of data that requires login authentication such as social networks. Collect facebook full access token of account.",
        "Personal Agent web-frontend: Part of the Personal Agent project, personalized data mining, using resources from the user's own computer. Personal Agent web-frontend is in the application layer to manage the collected data, statistics and all source to collect of user.",
        "Blocking paywall extension: Chromium-core extension for blocking the payment required in some Newspaper (for data collection module)"
      ]
    },
    {
      "id": 12,
      "position": "Java Software Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "Jun 2021 - Jul 2022 · 1 yr 2 mos",
      "type": "Work",
      "description": [
        "Backend modules:",
        "• All about Data Extraction module (Worker, manager, queue, document parser, ...): Collecting all kinds of data on social networks on demand. Manage the workers to collect. Data stored at MongoDB and managed data at Postgree. Workers, using http, selenium depend on Rule template sepecified, are given the option to use proxies to avoid problems with blocking requests.",
        "• Realtime metasearch: Quickly search results related to keywords on search systems. Handles blocking requests (Redis cache, autohealing), automatically scaling according to requests received and resources used.",
        "• Personal Agent web-backend: Part of the Personal Agent project, personalized data mining, using resources from the user's own computer. Personal Agent web is in the application layer to manage the collected data, statistics and all source to collect of user."
      ]
    },
    {
      "id": 13,
      "position": "Python Engineer",
      "employer": "Saltlux (솔트룩스)",
      "date": "May 2021 - Jul 2022 · 1 yr 3 mos",
      "type": "Work",
      "description": [
        "Internal Software:",
        "• Social Accounts Manager (windows application):",
        "• Get cookies and api tokens on a large number of accounts automatically.",
        "• Auto create accounts and get account info to crawl data (social network).",
        "• Automate all work if possible in the business."
      ]
    },
    {
      "id": 14,
      "company": true,
      "position": "METI Government of JAPAN, Internship Program (経済産業省　国際化促進インターンシップ事業)",
      "employer": "GRAVITY Corporation (グラビティ株式会社)",
      "date": "Dec 2020 - Feb 2021 · 3 mos",
      "type": "Work",
      "description": [
        "This internship was approved by the METI Japan Internship program, organized by METI Government of Japan",
        "• Acquired knowledge about Blockchain, Web 3.0, Smart contract through internal training conferences",
        "• Learned deeply about Scrum and Agile software development methods.",
        "• Worked under the supervision of CTO",
        "• Contributed to the company's first product in the education sector"
      ]
    },
    {
      "id": 15,
      "company": true,
      "position": "PHP Web Developer",
      "employer": "WeSports",
      "date": "Apr 2019 - Jun 2020 · 1 yr 3 mos",
      "type": "Work",
      "description": [
        "•  Worked with Wordpress to create and maintain dynamic websites and web applications",
        "•  Deployed Wordpress on Apache servers and used jQuery for front-end interactivity",
        "•  Developed software solutions using PHP frameworks, SQL databases, and object-oriented programming",
        "•  Used Git for version control and collaboration"
      ]
    }
  ],
  "skills": [{
      "category": "programming",
      "name": "Programming Languages",
      "items": ["Java", "NodeJS", "Golang", "Python", "C#"],
      "extraclass": "li25"
    },
    {
      "category": "cloud-platforms",
      "name": "Cloud Platforms",
      "items": ["AWS", "Azure", "GCP"],
      "extraclass": "li25"
    },
    {
      "category": "database",
      "name": "Database",
      "items": ["MySQL", "MariaDB", "MongoDB", "SQLite", "Postgres", "Redis", "Kafka"],
      "extraclass": "li50"
    },
    {
      "category": "infras-tools",
      "name": "Platform",
      "items": ["Terraform", "Terragrunt", "Packer", "Ansible", "Ceph", "CloudFormation", "Proxmox"],
      "extraclass": "li25"
    },
    {
      "category": "cicd-tools",
      "name": "CI/CD",
      "items": ["Gitlab CI", "ArgoCD", "Jenkins", "TravisCI", "Github Actions", "Azure Pipeline"],
      "extraclass": "li25"
    },
    {
      "category": "observability-tools",
      "name": "Observability",
      "items": ["Promtail-Loki-Grafana", "Elasticsearch-Loki-Grafana", "Prometheus-Thanos", "Jaeger", "DataDog", "NewRelic"],
      "extraclass": "li50"
    },
    {
      "category": "security",
      "name": "Security",
      "items": ["Vault Warden", "Hashicorp Vault", "OPA GateKeeper", "Snyk", "Sonarqube", "Trivy", "ZAP Operator", "Checkpoint CloudGuard", "AWS WAF", "Automation WAF"],
      "extraclass": "li66"
    },
    {
      "category": "container-tools",
      "name": "Container Tools",
      "items": ["Docker", "Kubernetes", "Helm", "KEDA", "Kapenter", "Istio", "Knative"],
      "extraclass": "li33"
    }
    
  ],
  "certifications": {
    "title": "Certifications",
    "description": "Click to see more certifications",
    "link": "https://www.linkedin.com/in/congson99/details/certifications/",
    "items": [{
        "name": "IBM DevOps and Software Engineering Specialization",
        "image": "common/img/IBM-icon.jpg",
        "link": "https://www.coursera.org/account/accomplishments/specialization/certificate/GZLCQK9NM36N"
      },
      {
        "name": "DevOps on AWS Specialization",
        "image": "common/img/Udemy-icon.jpg",
        "link": "https://www.coursera.org/account/accomplishments/specialization/certificate/ZDRLWB4QQ7XH"
      },
      {
        "name": "Core Infrastructure",
        "image": "common/img/Google-icon.jpg",
        "link": "https://www.coursera.org/account/accomplishments/certificate/VEBM4EY9H969"
      },
      {
        "name": "Continuous Integration and Continuous Delivery (CI/CD)",
        "image": "common/img/IBM-icon.jpg",
        "link": "https://www.coursera.org/account/accomplishments/certificate/R7WJJKU5U4GD"
      },
      {
        "name": "Python for Data Science and AI",
        "image": "common/img/IBM-icon.jpg",
        "link": "https://www.credly.com/badges/59286e28-5fd4-40d4-877a-797385dc4014/linked_in_profile"
      },
      {
        "name": "Python For Data Analysis, Data Science & ML With Pandas",
        "image": "common/img/Udemy-icon.jpg",
        "link": "https://ude.my/UC-6dbad681-7f62-4160-b2f0-b3890cf63984/"
      },
      {
        "name": "APTIS - C level (CERF)",
        "image": "common/img/BC-icon.jpg",
        "link": "#"
      }
    ]
  },
  "education": [{
      "degree": "International Business Economics",
      "school": "Foreign trade university",
      "date": "Aug 2017 - Mar 2021"
    }
  ]
}